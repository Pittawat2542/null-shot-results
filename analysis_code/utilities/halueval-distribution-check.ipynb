{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T04:03:38.216395Z",
     "start_time": "2024-04-25T04:03:38.188250Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import ujson"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:00:48.638198Z",
     "start_time": "2024-04-25T04:00:48.636215Z"
    }
   },
   "cell_type": "code",
   "source": "root_results_path = Path(\"results\")",
   "id": "b12711ebea720bdf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:01:00.878281Z",
     "start_time": "2024-04-25T04:01:00.875643Z"
    }
   },
   "cell_type": "code",
   "source": "models = [model for model in root_results_path.iterdir() if model.is_dir()]",
   "id": "6e2dd89e79518bb8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:01:28.315083Z",
     "start_time": "2024-04-25T04:01:28.313238Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_models = [model for model in models if not any([model.name.startswith(prefix) for prefix in [\"qwen\", \"pythia\", \"llama\"]])]",
   "id": "42800559634a7376",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T04:09:40.032870Z",
     "start_time": "2024-04-25T04:08:28.075197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in filtered_models:\n",
    "    tasks = [\"halueval-qa\", \"halueval-dialogue\", \"halueval-summarization\"]\n",
    "    for task in tasks:\n",
    "        task_path = model / task\n",
    "        for pe in [pe for pe in task_path.iterdir() if pe.is_dir()]:\n",
    "            if pe.is_dir():\n",
    "                yes_count = 0\n",
    "                files = [file for file in pe.iterdir() if file.is_file()]\n",
    "                for file in files:\n",
    "                    with open(file, \"r\") as f:\n",
    "                        data = ujson.load(f)\n",
    "                    if data.get(\"label\") == \"A\":\n",
    "                        yes_count += 1\n",
    "                print(f\"{model.name} {task} {pe.name} {yes_count}/{len(files)} = {yes_count/len(files)*100:.2f}%\")"
   ],
   "id": "6f065d38a14c3728",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-pro-chat halueval-qa zero-shot 5002/10001 = 50.01%\n",
      "gemini-pro-chat halueval-qa null-shot 5002/10001 = 50.01%\n",
      "gemini-pro-chat halueval-dialogue zero-shot 5058/10001 = 50.57%\n",
      "gemini-pro-chat halueval-dialogue null-shot 5058/10001 = 50.57%\n",
      "gemini-pro-chat halueval-summarization zero-shot 4924/10001 = 49.24%\n",
      "gemini-pro-chat halueval-summarization null-shot 4924/10001 = 49.24%\n",
      "palm-2-chat halueval-qa zero-shot 5053/10001 = 50.52%\n",
      "palm-2-chat halueval-qa null-shot 5053/10001 = 50.52%\n",
      "palm-2-chat halueval-dialogue zero-shot 4986/10001 = 49.86%\n",
      "palm-2-chat halueval-dialogue null-shot 4986/10001 = 49.86%\n",
      "palm-2-chat halueval-summarization zero-shot 4909/10001 = 49.09%\n",
      "palm-2-chat halueval-summarization null-shot 4909/10001 = 49.09%\n",
      "claude-3-opus halueval-qa zero-shot 5016/10001 = 50.15%\n",
      "claude-3-opus halueval-qa null-shot 5016/10001 = 50.15%\n",
      "claude-3-opus halueval-dialogue zero-shot 5029/10001 = 50.28%\n",
      "claude-3-opus halueval-dialogue null-shot 5016/10001 = 50.15%\n",
      "claude-3-opus halueval-summarization zero-shot 4923/10001 = 49.23%\n",
      "claude-3-opus halueval-summarization null-shot 4923/10001 = 49.23%\n",
      "claude-2.1 halueval-qa zero-shot 5014/10001 = 50.13%\n",
      "claude-2.1 halueval-qa null-shot 5014/10001 = 50.13%\n",
      "claude-2.1 halueval-dialogue zero-shot 5034/10001 = 50.33%\n",
      "claude-2.1 halueval-dialogue null-shot 5034/10001 = 50.33%\n",
      "claude-2.1 halueval-summarization zero-shot 4928/10001 = 49.28%\n",
      "claude-2.1 halueval-summarization null-shot 4928/10001 = 49.28%\n",
      "palm-2-text halueval-qa zero-shot 5013/10001 = 50.12%\n",
      "palm-2-text halueval-qa null-shot 5016/10001 = 50.15%\n",
      "palm-2-text halueval-dialogue zero-shot 5024/10001 = 50.23%\n",
      "palm-2-text halueval-dialogue null-shot 5025/10001 = 50.24%\n",
      "palm-2-text halueval-summarization zero-shot 4930/10001 = 49.30%\n",
      "palm-2-text halueval-summarization null-shot 4923/10001 = 49.23%\n",
      "claude-3-haiku halueval-qa zero-shot 5135/10001 = 51.34%\n",
      "claude-3-haiku halueval-qa null-shot 5135/10001 = 51.34%\n",
      "claude-3-haiku halueval-dialogue zero-shot 4993/10001 = 49.93%\n",
      "claude-3-haiku halueval-dialogue null-shot 4993/10001 = 49.93%\n",
      "claude-3-haiku halueval-summarization zero-shot 5019/10001 = 50.18%\n",
      "claude-3-haiku halueval-summarization null-shot 5019/10001 = 50.18%\n",
      "gemini-pro-text halueval-qa zero-shot 4956/10001 = 49.56%\n",
      "gemini-pro-text halueval-qa null-shot 4956/10001 = 49.56%\n",
      "gemini-pro-text halueval-dialogue zero-shot 4907/10001 = 49.07%\n",
      "gemini-pro-text halueval-dialogue null-shot 4907/10001 = 49.07%\n",
      "gemini-pro-text halueval-summarization zero-shot 5050/10001 = 50.49%\n",
      "gemini-pro-text halueval-summarization null-shot 5050/10001 = 50.49%\n",
      "gpt-4-turbo halueval-qa zero-shot 5016/10001 = 50.15%\n",
      "gpt-4-turbo halueval-qa null-shot 5016/10001 = 50.15%\n",
      "gpt-4-turbo halueval-dialogue zero-shot 5025/10001 = 50.24%\n",
      "gpt-4-turbo halueval-dialogue null-shot 5025/10001 = 50.24%\n",
      "gpt-4-turbo halueval-summarization zero-shot 4926/10001 = 49.26%\n",
      "gpt-4-turbo halueval-summarization null-shot 4926/10001 = 49.26%\n",
      "gpt-3.5-turbo halueval-qa zero-shot 5016/10001 = 50.15%\n",
      "gpt-3.5-turbo halueval-qa null-shot 5016/10001 = 50.15%\n",
      "gpt-3.5-turbo halueval-dialogue zero-shot 5024/10001 = 50.23%\n",
      "gpt-3.5-turbo halueval-dialogue null-shot 5024/10001 = 50.23%\n",
      "gpt-3.5-turbo halueval-summarization zero-shot 4924/10001 = 49.24%\n",
      "gpt-3.5-turbo halueval-summarization null-shot 4924/10001 = 49.24%\n",
      "claude-3-sonnet halueval-qa zero-shot 4925/10001 = 49.25%\n",
      "claude-3-sonnet halueval-qa null-shot 4940/10001 = 49.40%\n",
      "claude-3-sonnet halueval-dialogue zero-shot 5057/10001 = 50.56%\n",
      "claude-3-sonnet halueval-dialogue null-shot 5057/10001 = 50.56%\n",
      "claude-3-sonnet halueval-summarization zero-shot 4927/10001 = 49.27%\n",
      "claude-3-sonnet halueval-summarization null-shot 4928/10001 = 49.28%\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "68afa9861277b447"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
