{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:05:27.598635Z",
     "start_time": "2024-08-01T11:05:27.595743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd"
   ],
   "id": "5880b5ceaed75821",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:05:27.769268Z",
     "start_time": "2024-08-01T11:05:27.767313Z"
    }
   },
   "cell_type": "code",
   "source": "root_path = Path.cwd().parent / \"results\"",
   "id": "2ca2866047584034",
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-01T11:05:27.937367Z",
     "start_time": "2024-08-01T11:05:27.933551Z"
    }
   },
   "source": [
    "def is_not_hallucination(response, model):\n",
    "    gpt_model = \"I'm sorry, but\" in response and (\n",
    "            \"Examples\" in response or \"example\" in response or \"examples\" in response)\n",
    "\n",
    "    gemini_model_part = \"provided context\" in response or \"provided text\" in response or \"information\" in response\n",
    "    gemini_model = (\"does not mention\" in response and gemini_model_part) or (\n",
    "            \"does not contain\" in response and gemini_model_part) or (\n",
    "                           \"not available\" in response and gemini_model_part) or (\n",
    "                           \"could not extract\" in response and gemini_model_part) or (\n",
    "                           \"i cannot answer\" in response and gemini_model_part) or (\n",
    "                           \"cannot be found\" in response and gemini_model_part)\n",
    "    claude_model = (\"I apologize, but I don't have access to\" in response) or (\n",
    "            \"I'm afraid I don't have enough context\" in response) or (\n",
    "                           \"Unfortunately I do not have enough context\" in response) or (\n",
    "                           \"Unfortunately, without having access to\" in response) or (\n",
    "                           \"Unfortunately, I cannot provide a definitive\" in response)\n",
    "\n",
    "    if model in [\"gpt-3.5-turbo\", \"gpt-4-turbo\"]:\n",
    "        return gpt_model\n",
    "    if model in [\"gemini-pro-text\", \"gemini-pro-chat\"]:\n",
    "        return gemini_model\n",
    "    if model in [\"claude-2.1\", \"claude-3-haiku\", 'claude-3-sonnet', 'claude-3-opus']:\n",
    "        return claude_model\n",
    "\n",
    "    return gpt_model or gemini_model or claude_model"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:05:28.121818Z",
     "start_time": "2024-08-01T11:05:28.119527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tasks = [\"anli\", \"aqua\", \"gsm8k\", \"race-h\", \"race-m\", \"strategyqa\", \"triviaqa\", \"winogrande\", \"halueval-dialogue\",\n",
    "         \"halueval-general\", \"halueeval-qa\", \"halueval-summarization\", \"math-algebra\", \"math-count-prob\",\n",
    "         \"math-geometry\", \"math-int-algebra\", \"math-number\", \"math-pre-algebra\", \"math-pre-calc\"]"
   ],
   "id": "d51a9f8f93dfe0a7",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:05:28.320663Z",
     "start_time": "2024-08-01T11:05:28.315364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyse(task, model):\n",
    "    task_path = model / task\n",
    "    null_shot_path = task_path / \"null-shot\"\n",
    "    zero_shot_path = task_path / \"zero-shot\"\n",
    "    null_shot_files = sorted(list(null_shot_path.glob(\"*.json\")))\n",
    "    null_shot_files = null_shot_files[:-1]\n",
    "    baseline_files = sorted(list(zero_shot_path.glob(\"*.json\")))\n",
    "    baseline_files = baseline_files[:-1]\n",
    "    files = list(zip(null_shot_files, baseline_files))\n",
    "\n",
    "    output_path = Path.cwd().parent / Path(\"analysis_results\") / \"hallucination\" / model\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_count = 0\n",
    "    improve_only_count = 0\n",
    "    all_total = 0\n",
    "    improve_only_total = 0\n",
    "    for idx in range(len(files)):\n",
    "        null_shot_file = files[idx][0]\n",
    "        baseline_file = files[idx][1]\n",
    "        with open(null_shot_file, 'r') as f:\n",
    "            null_shot_data = json.load(f)\n",
    "            null_shot_response = null_shot_data[\"response\"]\n",
    "            null_shot_is_correct = null_shot_data[\"is_correct\"]\n",
    "            all_total += 1\n",
    "            with open(baseline_file, 'r') as f:\n",
    "                baseline_data = json.load(f)\n",
    "                baseline_is_correct = baseline_data[\"is_correct\"]\n",
    "            if not baseline_is_correct and null_shot_is_correct:\n",
    "                improve_only_total += 1\n",
    "        if (not is_not_hallucination(null_shot_response, model)) and ('\"Examples\"' in null_shot_response or \"examples section\" in null_shot_response):\n",
    "            all_count += 1\n",
    "            if not baseline_is_correct and null_shot_is_correct:\n",
    "                improve_only_count += 1\n",
    "            \n",
    "                \n",
    "    print(f\"hallucination count: {count}/{total}\")\n",
    "    return all_count, all_total, improve_only_count, improve_only_total"
   ],
   "id": "283960e925a692e7",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:05:28.518036Z",
     "start_time": "2024-08-01T11:05:28.514997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = [model for model in root_path.iterdir() if\n",
    "          model.is_dir() and not model.stem.startswith(\"pythia\") and not model.stem.startswith(\n",
    "              \"qwen\") and not model.stem.startswith(\"llama\")]"
   ],
   "id": "d20b31135634934a",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:07:18.474477Z",
     "start_time": "2024-08-01T11:05:28.964495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "report = {\n",
    "    \"model\": [],\n",
    "    \"task\": [],\n",
    "    \"hallucination_count\": [],\n",
    "    \"total_count\": [],\n",
    "    \"hallucination_improve_only_count\": [],\n",
    "    \"total_improve_only_count\": []\n",
    "}\n",
    "\n",
    "for t in tasks:\n",
    "    for model in models:\n",
    "        m = model.parts[-1]\n",
    "        print(f\"== task: {t}, model: {m} ==\")\n",
    "        a_count, a_total, i_count, i_total = analyse(t, model)\n",
    "        report[\"model\"].append(m)\n",
    "        report[\"task\"].append(t)\n",
    "        report[\"hallucination_count\"].append(a_count)\n",
    "        report[\"total_count\"].append(a_total)\n",
    "        report[\"hallucination_improve_only_count\"].append(i_count)\n",
    "        report[\"total_improve_only_count\"].append(i_total)"
   ],
   "id": "1390fa30d2cc5562",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== task: anli, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: anli, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: anli, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: anli, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: anli, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: anli, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: anli, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: anli, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: anli, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: anli, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: aqua, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: aqua, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: aqua, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: aqua, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: aqua, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: aqua, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: aqua, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: aqua, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: aqua, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: aqua, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: gsm8k, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: gsm8k, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: gsm8k, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: gsm8k, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: gsm8k, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: gsm8k, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: gsm8k, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: gsm8k, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: gsm8k, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: gsm8k, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: race-h, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: race-h, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: race-h, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: race-h, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: race-h, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: race-h, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: race-h, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: race-h, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: race-h, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: race-h, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: race-m, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: race-m, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: race-m, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: race-m, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: race-m, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: race-m, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: race-m, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: race-m, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: race-m, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: race-m, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: strategyqa, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: strategyqa, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: strategyqa, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: strategyqa, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: strategyqa, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: strategyqa, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: strategyqa, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: strategyqa, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: strategyqa, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: strategyqa, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: triviaqa, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: triviaqa, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: triviaqa, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: triviaqa, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: triviaqa, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: triviaqa, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: triviaqa, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: triviaqa, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: triviaqa, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: triviaqa, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: winogrande, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: winogrande, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: winogrande, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: winogrande, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: winogrande, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: winogrande, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: winogrande, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: winogrande, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: winogrande, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: winogrande, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-dialogue, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-dialogue, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-dialogue, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-dialogue, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-dialogue, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-dialogue, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-dialogue, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-dialogue, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-dialogue, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-dialogue, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-general, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-general, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-general, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-general, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-general, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-general, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-general, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-general, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-general, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-general, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: halueeval-qa, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: halueeval-qa, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: halueeval-qa, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: halueeval-qa, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: halueeval-qa, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: halueeval-qa, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: halueeval-qa, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: halueeval-qa, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: halueeval-qa, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: halueeval-qa, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-summarization, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-summarization, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-summarization, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-summarization, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-summarization, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-summarization, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-summarization, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-summarization, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-summarization, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: halueval-summarization, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: math-algebra, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-algebra, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-algebra, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: math-algebra, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: math-algebra, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-algebra, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: math-algebra, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-algebra, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-algebra, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-algebra, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: math-count-prob, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-count-prob, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-count-prob, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: math-count-prob, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: math-count-prob, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-count-prob, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: math-count-prob, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-count-prob, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-count-prob, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-count-prob, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: math-geometry, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-geometry, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-geometry, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: math-geometry, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: math-geometry, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-geometry, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: math-geometry, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-geometry, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-geometry, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-geometry, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: math-int-algebra, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-int-algebra, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-int-algebra, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: math-int-algebra, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: math-int-algebra, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-int-algebra, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: math-int-algebra, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-int-algebra, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-int-algebra, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-int-algebra, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: math-number, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-number, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-number, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: math-number, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: math-number, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-number, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: math-number, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-number, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-number, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-number, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-algebra, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-algebra, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-algebra, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-algebra, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-algebra, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-algebra, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-algebra, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-algebra, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-algebra, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-algebra, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-calc, model: gemini-pro-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-calc, model: palm-2-chat ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-calc, model: claude-3-opus ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-calc, model: claude-2.1 ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-calc, model: palm-2-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-calc, model: claude-3-haiku ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-calc, model: gemini-pro-text ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-calc, model: gpt-4-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-calc, model: gpt-3.5-turbo ==\n",
      "hallucination count: 69/546\n",
      "== task: math-pre-calc, model: claude-3-sonnet ==\n",
      "hallucination count: 69/546\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:07:18.477843Z",
     "start_time": "2024-08-01T11:07:18.475477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(report)\n",
    "df = df[df[\"total_count\"] != 0]"
   ],
   "id": "3e8695a2c751fec8",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:07:18.480861Z",
     "start_time": "2024-08-01T11:07:18.478689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['all_percentage'] = (df['hallucination_count'] / df['total_count']) * 100\n",
    "df['improve_only_percentage'] = (df['hallucination_improve_only_count'] / df['total_improve_only_count']) * 100"
   ],
   "id": "b46045b7aa31ba9e",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:07:18.484212Z",
     "start_time": "2024-08-01T11:07:18.481922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df['all_percentage'].mean(), df['all_percentage'].std())\n",
    "print(df['improve_only_percentage'].mean(), df['improve_only_percentage'].std())"
   ],
   "id": "55ff37ed07b06df1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.95252755638885 27.925553789974636\n",
      "16.12400431701438 28.63227225443099\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:07:18.490994Z",
     "start_time": "2024-08-01T11:07:18.484648Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_csv(Path.cwd().parent / \"analysis_results\" / \"hallucination_count.csv\", index=False)",
   "id": "dcad094afec191a5",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:13:09.187529Z",
     "start_time": "2024-08-01T11:13:09.184597Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.sort_values(by='all_percentage', ascending=False)",
   "id": "5ff86f3217db048e",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:14:27.590218Z",
     "start_time": "2024-08-01T11:14:27.581627Z"
    }
   },
   "cell_type": "code",
   "source": "df.groupby('task').agg({'hallucination_count': 'sum', 'total_count': 'sum', 'hallucination_improve_only_count': 'sum', 'total_improve_only_count': 'sum'}).sort_values(by='hallucination_count', ascending=False)",
   "id": "91869cac102e553d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        hallucination_count  total_count  \\\n",
       "task                                                       \n",
       "strategyqa                             6216        22900   \n",
       "race-h                                 4292        34980   \n",
       "gsm8k                                  3140        13190   \n",
       "winogrande                             2908        12670   \n",
       "triviaqa                               2788        10000   \n",
       "race-m                                 2077        14360   \n",
       "anli                                   1695        12000   \n",
       "math-algebra                           1687        11870   \n",
       "math-int-algebra                       1529         9030   \n",
       "math-pre-algebra                       1325         8710   \n",
       "halueval-dialogue                      1101       100000   \n",
       "math-number                            1074         5400   \n",
       "math-pre-calc                           939         5460   \n",
       "math-count-prob                         818         4740   \n",
       "math-geometry                           759         4790   \n",
       "aqua                                    677         2540   \n",
       "halueval-general                         90        45070   \n",
       "halueval-summarization                    4       100000   \n",
       "\n",
       "                        hallucination_improve_only_count  \\\n",
       "task                                                       \n",
       "strategyqa                                           417   \n",
       "race-h                                               397   \n",
       "gsm8k                                                234   \n",
       "winogrande                                           131   \n",
       "triviaqa                                              17   \n",
       "race-m                                               175   \n",
       "anli                                                 252   \n",
       "math-algebra                                         155   \n",
       "math-int-algebra                                     104   \n",
       "math-pre-algebra                                      97   \n",
       "halueval-dialogue                                     47   \n",
       "math-number                                          125   \n",
       "math-pre-calc                                         63   \n",
       "math-count-prob                                       75   \n",
       "math-geometry                                         61   \n",
       "aqua                                                  77   \n",
       "halueval-general                                       3   \n",
       "halueval-summarization                                 0   \n",
       "\n",
       "                        total_improve_only_count  \n",
       "task                                              \n",
       "strategyqa                                  1428  \n",
       "race-h                                      2574  \n",
       "gsm8k                                       1208  \n",
       "winogrande                                   804  \n",
       "triviaqa                                     181  \n",
       "race-m                                       906  \n",
       "anli                                         949  \n",
       "math-algebra                                1005  \n",
       "math-int-algebra                             513  \n",
       "math-pre-algebra                             657  \n",
       "halueval-dialogue                           5103  \n",
       "math-number                                  417  \n",
       "math-pre-calc                                287  \n",
       "math-count-prob                              315  \n",
       "math-geometry                                280  \n",
       "aqua                                         305  \n",
       "halueval-general                             594  \n",
       "halueval-summarization                      5850  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hallucination_count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>hallucination_improve_only_count</th>\n",
       "      <th>total_improve_only_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>strategyqa</th>\n",
       "      <td>6216</td>\n",
       "      <td>22900</td>\n",
       "      <td>417</td>\n",
       "      <td>1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race-h</th>\n",
       "      <td>4292</td>\n",
       "      <td>34980</td>\n",
       "      <td>397</td>\n",
       "      <td>2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsm8k</th>\n",
       "      <td>3140</td>\n",
       "      <td>13190</td>\n",
       "      <td>234</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winogrande</th>\n",
       "      <td>2908</td>\n",
       "      <td>12670</td>\n",
       "      <td>131</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triviaqa</th>\n",
       "      <td>2788</td>\n",
       "      <td>10000</td>\n",
       "      <td>17</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race-m</th>\n",
       "      <td>2077</td>\n",
       "      <td>14360</td>\n",
       "      <td>175</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anli</th>\n",
       "      <td>1695</td>\n",
       "      <td>12000</td>\n",
       "      <td>252</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math-algebra</th>\n",
       "      <td>1687</td>\n",
       "      <td>11870</td>\n",
       "      <td>155</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math-int-algebra</th>\n",
       "      <td>1529</td>\n",
       "      <td>9030</td>\n",
       "      <td>104</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math-pre-algebra</th>\n",
       "      <td>1325</td>\n",
       "      <td>8710</td>\n",
       "      <td>97</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>halueval-dialogue</th>\n",
       "      <td>1101</td>\n",
       "      <td>100000</td>\n",
       "      <td>47</td>\n",
       "      <td>5103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math-number</th>\n",
       "      <td>1074</td>\n",
       "      <td>5400</td>\n",
       "      <td>125</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math-pre-calc</th>\n",
       "      <td>939</td>\n",
       "      <td>5460</td>\n",
       "      <td>63</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math-count-prob</th>\n",
       "      <td>818</td>\n",
       "      <td>4740</td>\n",
       "      <td>75</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math-geometry</th>\n",
       "      <td>759</td>\n",
       "      <td>4790</td>\n",
       "      <td>61</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aqua</th>\n",
       "      <td>677</td>\n",
       "      <td>2540</td>\n",
       "      <td>77</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>halueval-general</th>\n",
       "      <td>90</td>\n",
       "      <td>45070</td>\n",
       "      <td>3</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>halueval-summarization</th>\n",
       "      <td>4</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>5850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T11:15:39.963649Z",
     "start_time": "2024-08-01T11:15:39.957169Z"
    }
   },
   "cell_type": "code",
   "source": "df.groupby('model').agg({'hallucination_count': 'sum', 'total_count': 'sum', 'hallucination_improve_only_count': 'sum', 'total_improve_only_count': 'sum'}).sort_values(by='hallucination_count', ascending=False)",
   "id": "492288c9bc2110e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 hallucination_count  total_count  \\\n",
       "model                                               \n",
       "claude-3-haiku                 14293        41771   \n",
       "claude-3-sonnet                 7831        41771   \n",
       "claude-3-opus                   6815        41771   \n",
       "gpt-3.5-turbo                   2204        41771   \n",
       "claude-2.1                      1063        41771   \n",
       "gemini-pro-chat                  326        41771   \n",
       "gemini-pro-text                  309        41771   \n",
       "palm-2-chat                      205        41771   \n",
       "gpt-4-turbo                       73        41771   \n",
       "palm-2-text                        0        41771   \n",
       "\n",
       "                 hallucination_improve_only_count  total_improve_only_count  \n",
       "model                                                                        \n",
       "claude-3-haiku                               1187                      3145  \n",
       "claude-3-sonnet                               515                      3536  \n",
       "claude-3-opus                                 269                      2968  \n",
       "gpt-3.5-turbo                                 254                      3347  \n",
       "claude-2.1                                     61                      3092  \n",
       "gemini-pro-chat                                71                      1166  \n",
       "gemini-pro-text                                62                      1233  \n",
       "palm-2-chat                                     9                      1620  \n",
       "gpt-4-turbo                                     2                      1564  \n",
       "palm-2-text                                     0                      1705  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hallucination_count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>hallucination_improve_only_count</th>\n",
       "      <th>total_improve_only_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claude-3-haiku</th>\n",
       "      <td>14293</td>\n",
       "      <td>41771</td>\n",
       "      <td>1187</td>\n",
       "      <td>3145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-sonnet</th>\n",
       "      <td>7831</td>\n",
       "      <td>41771</td>\n",
       "      <td>515</td>\n",
       "      <td>3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-opus</th>\n",
       "      <td>6815</td>\n",
       "      <td>41771</td>\n",
       "      <td>269</td>\n",
       "      <td>2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>2204</td>\n",
       "      <td>41771</td>\n",
       "      <td>254</td>\n",
       "      <td>3347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-2.1</th>\n",
       "      <td>1063</td>\n",
       "      <td>41771</td>\n",
       "      <td>61</td>\n",
       "      <td>3092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-pro-chat</th>\n",
       "      <td>326</td>\n",
       "      <td>41771</td>\n",
       "      <td>71</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-pro-text</th>\n",
       "      <td>309</td>\n",
       "      <td>41771</td>\n",
       "      <td>62</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palm-2-chat</th>\n",
       "      <td>205</td>\n",
       "      <td>41771</td>\n",
       "      <td>9</td>\n",
       "      <td>1620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>73</td>\n",
       "      <td>41771</td>\n",
       "      <td>2</td>\n",
       "      <td>1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palm-2-text</th>\n",
       "      <td>0</td>\n",
       "      <td>41771</td>\n",
       "      <td>0</td>\n",
       "      <td>1705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "683ff8c468c5bf3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
