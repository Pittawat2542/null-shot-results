{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-11T11:49:36.565546Z",
     "start_time": "2024-02-11T11:49:36.562360Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.add(\"logs/{time}.log\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T11:49:39.364357Z",
     "start_time": "2024-02-11T11:49:39.350368Z"
    }
   },
   "id": "819916dfb0399427",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "root_path = Path(\"results\")\n",
    "model_paths = [root_path / \"gemini-pro-text\", root_path / \"gemini-pro-chat\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T11:49:40.027621Z",
     "start_time": "2024-02-11T11:49:40.023913Z"
    }
   },
   "id": "c4a812a35e08c591",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:41.166\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/457.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.169\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/441.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.172\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/314.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.179\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/908.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.190\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/270.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.192\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/374.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.196\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/211.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.199\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/1137.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.206\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/298.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.217\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/71.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.218\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/646.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.221\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/240.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.228\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/1127.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.230\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/684.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.235\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/734.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.251\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/453.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.255\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/686.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 799/1200 [00:00<00:00, 7982.89it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:41.270\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/1040.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.272\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/167.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.276\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/480.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.291\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/1139.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.293\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/1007.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot/566.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1200/1200 [00:00<00:00, 8265.53it/s]\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  5.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:41.333\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot-cot/163.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.340\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot-cot/374.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.346\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot-cot/1137.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.374\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot-cot/684.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.379\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot-cot/734.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.399\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot-cot/49.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.402\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot-cot/686.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████▊   | 823/1200 [00:00<00:00, 8221.60it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:41.424\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot-cot/480.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.442\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot-cot/1139.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.444\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot-cot/1007.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1200/1200 [00:00<00:00, 8072.06it/s]\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  5.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:41.469\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/457.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.472\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/441.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.475\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/314.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.490\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/163.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.497\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/374.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.503\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/1137.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.510\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/298.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.525\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/240.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.533\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/1127.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.535\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/684.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.539\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/734.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.559\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/686.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████▋   | 795/1200 [00:00<00:00, 7939.29it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:41.575\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/1040.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.576\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/167.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.580\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/480.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/1139.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.598\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/zero-shot-cot/1007.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1200/1200 [00:00<00:00, 8206.13it/s]\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  6.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:41.640\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot/163.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.647\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot/374.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.654\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot/1137.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.705\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot/686.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████▉   | 835/1200 [00:00<00:00, 8345.43it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:41.742\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot/1139.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.744\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/anli/null-shot/1007.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1200/1200 [00:00<00:00, 8505.10it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.25it/s]\u001B[A\u001B[A\n",
      "\n",
      " 12%|█▎        | 1/8 [00:00<00:04,  1.56it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:41.769\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/857.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.770\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/154.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.782\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/524.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.789\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/227.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.792\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/661.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: HIGH\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.797\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/155.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.804\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/934.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.814\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/353.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.819\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/344.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.822\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/329.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.831\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/218.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.836\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/490.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.842\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/404.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.852\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/29.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.853\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/825.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.855\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/87.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.865\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/588.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 832/1000 [00:00<00:00, 8272.28it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:41.881\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot/356.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8433.63it/s]\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  8.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:41.903\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot-cot/524.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.910\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot-cot/227.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.919\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot-cot/155.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.941\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot-cot/329.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.954\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot-cot/490.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.960\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot-cot/404.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.965\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot-cot/487.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.973\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot-cot/87.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:41.987\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot-cot/635.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 862/1000 [00:00<00:00, 8595.76it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.000\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot-cot/878.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.002\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot-cot/356.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8527.33it/s]\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  8.18it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.025\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot-cot/524.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.034\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot-cot/661.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.040\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot-cot/155.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.061\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot-cot/329.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.075\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot-cot/490.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.080\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot-cot/900.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.081\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot-cot/404.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.091\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot-cot/29.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.094\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/zero-shot-cot/87.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8896.70it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  8.34it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.130\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot/154.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.142\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot/524.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.157\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot/155.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.177\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot/329.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.184\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot/218.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.196\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot/404.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.207\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot/87.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 923/1000 [00:00<00:00, 9224.84it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.232\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot/878.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.234\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/triviaqa/null-shot/356.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 9066.51it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00,  8.39it/s]\u001B[A\u001B[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:01<00:03,  1.83it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1436 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.258\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/251.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.264\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/713.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.269\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/549.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.277\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/1395.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.293\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/712.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.295\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/315.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.310\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/1393.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.312\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/471.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/1171.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.319\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/1130.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.323\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/579.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.330\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/714.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.338\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/470.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.344\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/1214.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 725/1436 [00:00<00:00, 7247.24it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.351\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/473.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.355\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/598.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.356\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/609.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.357\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/1145.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.358\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/388.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.364\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/582.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.366\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/717.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.369\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/107.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.372\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/1173.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.373\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/845.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.377\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/844.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.379\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/106.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.381\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/254.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.386\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/1129.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.396\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/472.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.400\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/711.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.401\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/316.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.402\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/253.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.405\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/443.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.418\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/727.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.419\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/399.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.422\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/1139.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.423\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/730.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.426\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/1396.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.432\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/1174.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.436\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot/252.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1436/1436 [00:00<00:00, 7490.40it/s]\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  4.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1436 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.453\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/251.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.457\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/713.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.464\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/1205.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.465\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/16.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.472\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/318.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.484\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/1204.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.491\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/712.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.492\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/179.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.494\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/315.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.500\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/1208.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.510\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/471.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.519\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/579.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.527\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/714.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.530\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/1131.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.533\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/846.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.537\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/470.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 708/1436 [00:00<00:00, 7076.11it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.548\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/473.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.561\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/717.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.564\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/107.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.567\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/845.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.574\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/106.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.580\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/1129.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.590\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/472.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.594\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/711.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/316.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.597\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/253.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.599\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/443.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.601\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/843.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.613\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/1207.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.615\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/1206.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.619\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/730.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.622\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/1396.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.630\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot-cot/317.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1436/1436 [00:00<00:00, 7529.57it/s]\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  5.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1436 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.648\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/251.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.652\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/713.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.659\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/1205.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.672\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/122.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.677\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/1204.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.683\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/712.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.685\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/315.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.691\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/1208.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.701\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/471.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.710\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/579.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.715\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/581.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.717\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/578.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.719\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/714.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.726\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/470.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.729\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/1404.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.731\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/124.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.738\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/473.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 742/1436 [00:00<00:00, 7417.48it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.743\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/598.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.744\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/609.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.745\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/1145.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.746\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/388.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/582.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.757\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/107.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.760\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/1173.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.761\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/845.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.765\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/844.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.768\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/106.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.769\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/254.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.778\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/52.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.785\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/472.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.788\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/711.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.791\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/316.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.792\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/253.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.794\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/443.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.800\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/926.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.808\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/727.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.809\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/399.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.813\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/1139.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.814\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/730.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.816\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/120.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.817\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/1396.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.823\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/zero-shot-cot/1174.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1436/1436 [00:00<00:00, 7499.28it/s]\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  5.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1436 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.847\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/713.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.850\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/1419.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.858\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/1213.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.878\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/712.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.881\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/1422.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.902\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/579.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.910\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/714.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.917\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/470.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.929\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/473.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/598.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.934\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/609.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 778/1436 [00:00<00:00, 7771.69it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:42.960\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/106.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.966\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/1129.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.976\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/472.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.979\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/711.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.984\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/443.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:42.997\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/727.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.002\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/730.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.005\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/1396.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.013\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-m/null-shot/317.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1436/1436 [00:00<00:00, 7846.61it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]\u001B[A\u001B[A\n",
      "\n",
      " 38%|███▊      | 3/8 [00:01<00:03,  1.53it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/2290 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:43.039\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/841.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.049\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1233.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.052\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2223.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.056\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1419.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.057\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/61.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.062\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1069.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.064\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1194.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.066\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/772.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.071\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2080.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.077\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2106.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.078\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1045.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.080\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2055.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.085\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1291.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/134.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.104\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1140.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.105\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2081.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.107\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/335.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.113\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/40.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.118\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/99.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.124\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1475.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▍       | 568/2290 [00:00<00:00, 5675.12it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:43.134\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/774.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.138\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/109.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.139\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1350.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.144\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1239.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.147\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/830.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.150\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1628.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.153\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1960.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.154\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/406.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.155\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2161.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.156\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1608.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.157\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1521.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.159\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2177.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.160\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/294.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.167\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1848.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.182\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/554.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.184\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2208.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.186\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/915.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.188\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2249.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.190\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1609.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.191\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/112.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.192\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1961.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.194\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2005.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.197\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2117.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.198\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/132.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.199\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1238.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.204\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2087.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.204\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/734.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.211\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2245.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.224\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/958.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.229\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/977.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 1189/2290 [00:00<00:00, 5937.24it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:43.233\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/824.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.241\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1885.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.242\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1606.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.245\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/664.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.247\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1578.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.251\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1671.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.254\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/202.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.256\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/255.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.259\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/500.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.263\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1962.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.265\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2134.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.266\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2070.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.267\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1060.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.268\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/956.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.272\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/917.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.275\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1133.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.279\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/203.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: HIGH\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.283\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/757.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.285\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/184.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.292\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1996.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.296\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/126.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.298\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1810.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.306\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/880.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.309\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/838.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.310\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1948.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.311\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/642.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.324\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1769.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.325\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/249.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.325\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/38.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.328\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1801.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 1910/2290 [00:00<00:00, 6515.37it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:43.335\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1211.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.339\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1929.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.341\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1315.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.344\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1084.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.351\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/419.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.356\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1816.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.359\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/566.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.360\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/835.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.360\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/1800.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.364\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2001.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.369\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/141.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.371\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/507.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.374\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/803.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.380\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/643.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.381\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot/2236.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 2290/2290 [00:00<00:00, 6457.23it/s]\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/2290 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:43.394\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/2075.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.406\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1136.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.409\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/314.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.414\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/2223.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.417\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1419.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.418\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/61.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.422\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1069.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.426\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/772.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.430\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/2038.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.432\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/2080.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.445\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/2055.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.448\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1291.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.460\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1140.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.463\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/335.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.469\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/231.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.470\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/40.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.470\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/2214.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.487\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1658.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.491\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/774.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 609/2290 [00:00<00:00, 6086.41it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:43.495\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/109.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.497\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/365.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.498\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1350.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.505\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/830.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.512\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1608.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.513\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1521.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.514\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/294.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.517\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/2065.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.521\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1848.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.544\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1609.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.545\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/112.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1961.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.547\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/2005.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.552\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1238.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.563\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/2245.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.565\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/46.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.566\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/958.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1503.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.569\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1446.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.573\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1684.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.577\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1846.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.583\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1606.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.587\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1578.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████▊    | 1340/2290 [00:00<00:00, 6803.94it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:43.594\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/202.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.596\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/255.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.606\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/2134.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.611\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/2174.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.612\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/917.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.614\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/940.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.620\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/203.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: HIGH\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.623\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/757.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.634\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1144.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.637\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/126.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.638\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1810.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.646\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/880.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.648\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/838.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.650\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/642.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.671\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/176.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.672\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1006.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.677\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1929.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.679\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1315.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.682\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1084.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.687\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/321.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.689\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/419.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 2075/2290 [00:00<00:00, 7050.64it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:43.694\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/1007.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.701\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/589.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.709\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/141.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.711\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/507.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.712\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/229.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.714\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot-cot/803.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 2290/2290 [00:00<00:00, 6940.28it/s]\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  2.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/2290 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:43.731\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2075.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.745\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/314.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.750\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2223.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1419.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.759\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1069.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.761\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1194.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.763\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/772.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.767\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2038.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.769\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2080.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.775\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1045.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.776\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2055.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.783\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/134.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.795\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/40.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.811\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1658.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.818\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/109.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.821\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1350.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.828\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/830.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 31%|███       | 709/2290 [00:00<00:00, 7086.95it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:43.832\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1628.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.835\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/406.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.838\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1521.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.839\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/294.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.841\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2065.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.858\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1832.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.859\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/554.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.860\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2208.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.862\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/915.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.866\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1609.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.866\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/112.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.868\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1961.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.869\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2005.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.873\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/132.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.875\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1238.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.879\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2087.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.882\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2204.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.889\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/958.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.894\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/977.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.904\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1885.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.905\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1606.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.908\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/234.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.910\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1082.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.911\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1578.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.917\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1671.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.919\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/202.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.923\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1831.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.926\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/500.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 1426/2290 [00:00<00:00, 7133.66it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:43.932\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2134.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.934\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1125.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.938\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/917.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.944\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/203.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: HIGH\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.947\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/757.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.949\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/184.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.955\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1304.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.960\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1778.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.961\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/126.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.962\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1810.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.969\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/880.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.971\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/838.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.972\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/8.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.974\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/642.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.986\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/249.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.990\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1801.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.994\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/176.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:43.999\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1883.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.000\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1929.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.002\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1315.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.006\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1084.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.006\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1590.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.009\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1894.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.013\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/419.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.016\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1007.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.018\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1816.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.020\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/566.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.024\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2001.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.029\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/141.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████▌| 2193/2290 [00:00<00:00, 7374.52it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:44.032\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/507.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.034\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/803.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.039\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/1676.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.041\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/zero-shot-cot/2236.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 2290/2290 [00:00<00:00, 7301.13it/s]\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  2.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/2290 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:44.065\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1136.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.071\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/2223.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.075\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1419.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.079\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1069.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.083\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/772.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.088\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/2080.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.094\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/2106.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.096\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/2055.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.099\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1291.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.108\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1140.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.110\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/335.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.117\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/40.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.134\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1658.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.139\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/774.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.143\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/109.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.145\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1350.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 695/2290 [00:00<00:00, 6949.31it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:44.160\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/294.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.163\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/2065.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.186\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1609.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.187\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/112.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.188\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1961.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.190\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/2005.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.194\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1238.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.206\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/958.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.208\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1446.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.212\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1684.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.223\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/371.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.225\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1578.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.231\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/202.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.233\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/255.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.243\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/2134.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.248\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/917.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████▌   | 1504/2290 [00:00<00:00, 7614.94it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:44.254\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/891.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.256\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/203.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.259\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/757.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.269\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1144.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.272\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/126.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.280\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/880.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/838.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.284\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/642.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.305\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/176.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.306\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1006.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.308\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1211.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.312\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1929.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.313\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1315.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.317\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1084.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.321\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/321.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.324\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/419.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.327\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/1007.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.339\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/141.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.342\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/507.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.345\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/strategyqa/null-shot/803.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2290/2290 [00:00<00:00, 7578.92it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.00it/s]\u001B[A\u001B[A\n",
      "\n",
      " 50%|█████     | 4/8 [00:03<00:03,  1.08it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1267 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:44.368\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/441.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.371\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/744.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.384\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/420.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.424\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/743.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.433\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/1078.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.437\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/237.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.451\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/1077.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.455\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/238.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 848/1267 [00:00<00:00, 8475.00it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:44.462\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/1236.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.475\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/711.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.485\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/96.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.492\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/419.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.499\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/792.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.501\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/442.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.503\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/946.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.505\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot/710.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 8589.77it/s]\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  6.56it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1267 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:44.517\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/null-shot-cot/441.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.582\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/null-shot-cot/1078.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.586\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/null-shot-cot/237.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.589\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/null-shot-cot/127.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.599\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/null-shot-cot/1077.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.604\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/null-shot-cot/238.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 867/1267 [00:00<00:00, 8659.44it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:44.646\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/null-shot-cot/395.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.650\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/null-shot-cot/442.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 8791.82it/s]\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  6.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1267 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:44.667\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/441.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.669\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/744.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.720\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/743.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.727\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/1107.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.731\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/1078.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.734\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/237.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.746\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/1077.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.751\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/238.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.757\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/1236.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 888/1267 [00:00<00:00, 8876.71it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:44.771\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/711.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.780\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/96.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.788\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/419.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.796\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/442.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.798\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/946.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.800\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/zero-shot-cot/710.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 8849.74it/s]\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  6.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1267 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:44.880\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/null-shot/1078.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:44.895\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/winogrande/null-shot/1077.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 9327.27it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.78it/s]\u001B[A\u001B[A\n",
      "\n",
      " 62%|██████▎   | 5/8 [00:03<00:02,  1.25it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1319 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:45.004\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/zero-shot/778.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.020\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/zero-shot/779.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.021\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/zero-shot/1062.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.044\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/zero-shot/1165.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 861/1319 [00:00<00:00, 8604.00it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:45.052\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/zero-shot/413.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.084\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/zero-shot/727.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 8745.18it/s]\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  6.46it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1319 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 64%|██████▍   | 847/1319 [00:00<00:00, 8460.77it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:45.241\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/null-shot-cot/727.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.254\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/null-shot-cot/252.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 8663.90it/s]\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  6.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1319 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:45.346\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/zero-shot-cot/779.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.349\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/zero-shot-cot/1062.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▍    | 721/1319 [00:00<00:00, 7206.60it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:45.379\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/zero-shot-cot/413.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.380\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/zero-shot-cot/1099.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.409\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/zero-shot-cot/727.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 8161.79it/s]\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  6.21it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1319 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 65%|██████▍   | 857/1319 [00:00<00:00, 8567.09it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:45.533\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/null-shot/1099.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.565\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/gsm8k/null-shot/727.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 8563.49it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.27it/s]\u001B[A\u001B[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:04<00:01,  1.34it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 254/254 [00:00<00:00, 18716.02it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 254/254 [00:00<00:00, 16729.27it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 254/254 [00:00<00:00, 18201.21it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 254/254 [00:00<00:00, 18690.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 63.39it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/3498 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:45.666\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1823.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.668\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1120.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.671\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1435.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.678\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1874.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.680\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1462.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.685\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2171.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.695\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1589.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.697\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2448.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.699\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1771.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.708\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1675.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.710\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/705.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.714\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2848.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.715\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1337.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.716\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3473.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.722\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1710.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.726\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3280.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.732\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3279.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.736\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1356.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.746\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2043.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.749\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2239.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.755\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2452.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.756\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2844.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.757\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2453.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.758\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2845.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.760\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1506.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 457/3498 [00:00<00:00, 4569.59it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:45.768\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1681.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.773\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3192.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.777\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/677.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.778\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1212.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.781\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3278.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.785\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3281.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.786\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/323.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.792\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3110.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.793\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2701.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.795\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3472.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.798\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1336.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.802\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/704.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.804\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/76.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.806\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/712.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.813\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/155.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.815\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2259.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.818\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1875.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.822\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1121.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.825\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2356.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.826\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/47.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.830\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1487.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.832\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3286.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.833\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/324.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.835\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1491.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.836\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3443.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.846\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2507.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.851\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/719.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.858\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2004.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 1115/3498 [00:00<00:00, 5750.01it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:45.863\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1825.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.868\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3336.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.873\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1833.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.874\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/410.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.882\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/579.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.882\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/980.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.885\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/580.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.890\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2771.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.891\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/30.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.892\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3474.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.893\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2770.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.894\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/31.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.896\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/581.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.900\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/702.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.901\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/578.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.902\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/981.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.908\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1832.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.910\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2822.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.915\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1873.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.920\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1824.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.923\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2005.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.925\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3182.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.927\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1916.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.934\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1404.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.936\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1111.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.938\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2506.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.941\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2984.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.946\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3291.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.949\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1490.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.949\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3442.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.951\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3287.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.952\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/325.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.954\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1486.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.957\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2091.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.959\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1828.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 1764/3498 [00:00<00:00, 6084.14it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:45.962\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1153.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.964\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3181.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.971\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1112.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.976\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3178.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.981\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2657.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.985\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3441.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.990\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/12.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.994\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1082.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:45.996\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/32.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.000\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/582.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.003\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/982.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.004\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3123.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.009\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2159.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.012\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1831.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.013\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/384.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.015\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2821.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.019\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2175.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.021\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1489.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.023\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3288.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.025\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/49.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.025\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2358.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.031\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1826.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.032\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/48.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.035\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3289.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.036\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1488.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.038\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2174.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.040\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1164.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.043\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2820.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.044\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1830.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.045\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2508.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.048\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/891.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.051\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3122.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.057\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2772.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.061\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2355.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████▉   | 2406/3498 [00:00<00:00, 6208.53it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:46.067\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3285.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.076\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3179.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.081\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1113.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.088\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/649.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.090\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3180.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.095\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1335.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.099\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/212.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.100\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3125.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.102\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/711.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.105\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1323.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.108\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3109.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.110\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/678.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.113\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/785.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.114\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2173.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.117\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1876.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.118\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1175.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.120\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1437.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.121\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1122.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.124\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2846.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.125\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2145.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.126\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2450.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.126\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1786.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.131\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2954.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.139\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1790.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.143\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1211.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.154\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1179.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.157\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1591.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.158\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2217.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 3074/3498 [00:00<00:00, 6376.21it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:46.162\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2580.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.173\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/675.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.174\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1210.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.182\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1683.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.184\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/209.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.188\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3217.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.191\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1338.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.192\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2847.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.193\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2451.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.194\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1787.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.196\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1436.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.202\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3276.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.203\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2172.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.209\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2719.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.211\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1637.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.216\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/3124.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.223\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/1271.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.224\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot/2261.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 3498/3498 [00:00<00:00, 6195.46it/s]\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  1.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/3498 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:46.242\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1823.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.243\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1120.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.246\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1435.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.252\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1177.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.253\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1874.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.253\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/841.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.257\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2171.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.263\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2258.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.267\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1589.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.269\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2448.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.277\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1675.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.278\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/705.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.279\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1049.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.282\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1788.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.283\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2848.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.284\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1337.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.285\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3473.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.292\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1710.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.296\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3280.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.301\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3279.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.306\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/676.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.315\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2043.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2805.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.324\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2452.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.325\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2147.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.326\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2844.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.326\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2453.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.328\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2845.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.329\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1506.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.337\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1052.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▍        | 516/3498 [00:00<00:00, 5141.85it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:46.345\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1212.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.348\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3278.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.352\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3281.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.353\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/323.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1336.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.366\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2721.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.368\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/704.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.369\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/76.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.371\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/712.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.375\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2449.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.379\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/155.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.381\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2259.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.384\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1176.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.384\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1875.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.392\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2356.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.392\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/47.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.398\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3286.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.400\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1491.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.401\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3443.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.411\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2507.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.415\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/719.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.428\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1825.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 1194/3498 [00:00<00:00, 6103.79it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:46.439\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1833.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.448\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/579.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.449\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/980.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.451\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/580.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.458\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3474.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.459\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2770.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.461\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/581.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.465\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/578.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.466\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/981.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.472\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1832.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.475\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2822.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.480\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1873.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.485\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1824.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.490\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1445.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.497\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/718.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.500\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1111.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.501\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2506.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.507\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3291.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.509\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1490.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.510\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3442.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.511\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3287.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.514\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/11.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.518\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/46.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.518\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1828.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.529\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1112.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.533\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3178.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.537\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2657.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 1895/3498 [00:00<00:00, 6505.41it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:46.542\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3441.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.547\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/12.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.550\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1082.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.556\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/582.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.559\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3123.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.566\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1831.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.568\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2821.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.573\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2175.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.574\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1489.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.577\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3288.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.579\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/49.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.579\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2358.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.585\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1826.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.586\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/48.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.588\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3289.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.589\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1488.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.592\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2174.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.597\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2820.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.599\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1830.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.599\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2508.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.605\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3122.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.611\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2772.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.614\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2355.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.620\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3285.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.621\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2251.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.630\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3179.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.634\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1113.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 2571/3498 [00:00<00:00, 6603.86it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:46.643\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3180.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.646\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2260.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.648\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1335.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.651\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/212.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.653\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3125.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.655\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/711.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.662\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/678.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.665\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/785.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.666\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2173.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.669\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1876.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.670\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1175.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.673\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1437.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.674\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1122.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.676\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2846.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.677\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2450.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.678\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1786.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.682\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2954.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.690\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1790.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.693\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1211.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.704\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1179.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.710\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2580.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.713\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1178.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.720\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/675.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.721\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1210.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.729\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1050.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.732\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/209.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.735\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3217.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 94%|█████████▎| 3272/3498 [00:00<00:00, 6749.05it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:46.740\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1338.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.740\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2847.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.741\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2451.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.744\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/1436.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.745\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2471.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.750\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/2172.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.762\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/3124.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.763\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot-cot/985.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 3498/3498 [00:00<00:00, 6556.45it/s]\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:01<00:01,  1.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/3498 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:46.789\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1823.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.791\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1120.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.792\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1435.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.798\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1177.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.798\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1874.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.801\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1462.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.802\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2171.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.811\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1589.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.813\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2448.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.815\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1771.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.820\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/206.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.825\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1675.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.826\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/705.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.828\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1049.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.830\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2848.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.832\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1337.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.832\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3473.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.840\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1710.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.845\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3280.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.850\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3279.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.854\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1356.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.855\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/676.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.864\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2043.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.867\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2239.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.872\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2452.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.874\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2844.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.875\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2453.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.876\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2845.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.877\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1506.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.884\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1681.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▍        | 508/3498 [00:00<00:00, 5076.10it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:46.889\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3192.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.893\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/677.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.894\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1212.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.897\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3278.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.900\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3281.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.901\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/323.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.907\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3110.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.908\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2701.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.910\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3472.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.912\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/495.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.914\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1336.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.917\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/704.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.919\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/76.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.921\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/712.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.928\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/856.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.929\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/155.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.931\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2259.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.934\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1875.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.937\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1121.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.941\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2356.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.942\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/47.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.946\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1487.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.948\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3286.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.949\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/324.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.951\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1491.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.951\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3443.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.953\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3290.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.960\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3195.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.962\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2507.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.966\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/719.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.973\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2004.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.978\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1825.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.984\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3336.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 1170/3498 [00:00<00:00, 5983.39it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:46.990\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1833.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.991\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/410.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.998\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/579.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:46.999\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/980.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.001\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/580.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.004\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/754.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.006\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1448.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.007\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2771.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.008\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/30.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.009\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3474.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.011\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2770.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.011\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/31.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.013\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/581.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.017\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/702.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.018\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/578.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.019\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/981.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.025\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1832.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.027\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2822.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.033\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1873.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.037\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1824.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.040\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2005.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.043\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3182.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.044\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1916.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.058\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1111.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.064\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2506.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.071\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2984.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.075\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3291.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.077\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1490.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.078\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3442.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.079\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3287.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.080\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/325.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.082\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1486.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.086\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/46.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.086\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1828.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████     | 1769/3498 [00:00<00:00, 5852.37it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:47.092\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3181.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.099\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1112.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.102\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2769.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.104\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3178.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.108\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2657.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.112\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3441.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.116\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/12.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.120\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1082.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.121\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/32.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.126\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/582.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.128\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/982.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.129\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3123.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.134\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2159.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.137\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1831.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.137\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/384.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.139\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2821.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.143\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2175.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.145\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1489.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.147\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3288.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.149\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/49.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.149\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2358.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.155\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1826.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.156\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/48.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.158\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3289.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.160\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1488.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.162\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2174.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.164\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1164.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.166\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2820.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.168\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1830.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.169\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2508.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.171\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/891.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.180\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2772.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.183\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2355.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.188\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3285.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 2450/3498 [00:00<00:00, 6224.94it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:47.198\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3179.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.202\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1113.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.209\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/649.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.212\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3180.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.214\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2260.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.216\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1335.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.220\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/212.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.221\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3125.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.223\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/711.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.226\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1323.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.229\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3109.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.230\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/678.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.231\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1358.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.234\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/785.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.234\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2173.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.237\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1876.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.238\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1175.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.241\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1437.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.242\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1122.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.245\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2846.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.245\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2145.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.246\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2450.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.247\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1786.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.251\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2954.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.258\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1790.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.261\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1211.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.270\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1179.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.274\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2217.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.277\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2580.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.287\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/675.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.288\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1210.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 3168/3498 [00:00<00:00, 6564.45it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:47.298\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2555.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.298\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/209.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.302\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3217.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.306\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1338.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.306\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2847.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.307\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2451.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.308\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1787.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.316\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3276.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.317\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2172.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.322\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2719.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.324\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/1637.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.328\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/3124.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.329\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/985.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.336\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/zero-shot-cot/2261.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 3498/3498 [00:00<00:00, 6326.83it/s]\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  1.78it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/3498 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:47.386\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1209.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.387\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1823.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.389\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1435.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.394\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1177.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.395\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1874.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.398\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2171.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.406\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1589.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.409\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2274.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.413\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2809.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.416\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/210.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.418\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/705.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.421\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1788.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.422\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1337.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.428\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1710.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.432\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3280.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.438\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3279.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.442\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/676.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.449\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2043.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.457\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2844.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.460\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1506.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.466\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1681.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.470\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3192.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.473\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/677.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.474\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1212.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.477\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3278.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.480\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3281.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 620/3498 [00:00<00:00, 6195.43it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:47.486\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3110.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.487\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2701.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.490\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1789.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.491\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1336.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.493\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2721.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.495\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/704.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.497\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/712.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.504\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/155.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.507\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3274.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.514\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/47.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.520\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1491.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.521\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3443.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.541\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1960.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.546\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3336.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.558\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/579.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.560\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/580.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.564\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2771.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.566\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3474.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.567\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2770.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.569\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/581.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.573\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/578.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.574\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/981.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.579\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1832.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 41%|████      | 1423/3498 [00:00<00:00, 7272.85it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:47.583\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2822.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.589\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1873.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.590\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2249.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.593\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1609.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.594\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1824.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.597\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2005.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.599\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1916.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.605\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/718.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.608\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1111.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.616\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1490.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.617\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3442.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.623\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/46.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.632\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2417.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.633\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1112.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.637\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3178.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.643\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3441.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.647\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/12.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.654\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/243.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.656\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/582.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.665\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/384.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.671\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2175.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.672\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1489.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.676\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2358.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.678\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1718.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.680\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1719.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 2199/3498 [00:00<00:00, 7482.55it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:47.683\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/48.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.686\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1488.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.689\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2174.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.694\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1830.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.700\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3122.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.702\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1559.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.705\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2772.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.708\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2355.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.712\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1607.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.714\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2251.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.720\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2969.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.726\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1113.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.730\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2416.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.738\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2260.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.740\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1335.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.743\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/212.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.744\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3125.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.747\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/711.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.753\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3109.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.754\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/678.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.757\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2173.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.760\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1876.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.761\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1175.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.767\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2145.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.768\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1786.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.772\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1381.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.779\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1790.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 2948/3498 [00:00<00:00, 7463.57it/s]\u001B[A\u001B[A\u001B[A\u001B[32m2024-02-11 20:49:47.783\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1211.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.805\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3041.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.807\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1210.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.811\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3313.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.815\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1683.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.816\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/209.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.819\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2810.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.823\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1338.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.824\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2847.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.824\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2451.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.825\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1787.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: LOW\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.831\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1461.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.833\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3276.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.834\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/2172.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.842\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1637.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.851\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/3124.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.854\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1699.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: MEDIUM\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "\u001B[32m2024-02-11 20:49:47.859\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m13\u001B[0m - \u001B[1mCorrecting results/gemini-pro-text/race-h/null-shot/1271.json with ERROR: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\n",
      "block_reason: SAFETY\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: HIGH\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\u001B[0m\n",
      "100%|██████████| 3498/3498 [00:00<00:00, 7280.46it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\u001B[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.75s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1200/1200 [00:00<00:00, 9341.57it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  7.55it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1200/1200 [00:00<00:00, 9366.75it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  7.56it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1200/1200 [00:00<00:00, 9120.83it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  7.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1200/1200 [00:00<00:00, 9459.91it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00,  7.51it/s]\u001B[A\u001B[A\n",
      "\n",
      " 12%|█▎        | 1/8 [00:00<00:03,  1.88it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10577.87it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10079.24it/s]\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  9.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10198.67it/s]\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  9.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10168.58it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.88it/s]\u001B[A\u001B[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:02,  2.18it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1436 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1436/1436 [00:00<00:00, 9197.46it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  6.22it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1436 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1436/1436 [00:00<00:00, 8882.46it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  6.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1436 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1436/1436 [00:00<00:00, 9085.11it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  6.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1436 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1436/1436 [00:00<00:00, 8779.99it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.03it/s]\u001B[A\u001B[A\n",
      "\n",
      " 38%|███▊      | 3/8 [00:01<00:02,  1.81it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/2290 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 33%|███▎      | 754/2290 [00:00<00:00, 7531.64it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 2290/2290 [00:00<00:00, 8542.89it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  3.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/2290 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 36%|███▋      | 832/2290 [00:00<00:00, 8317.77it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 2290/2290 [00:00<00:00, 8681.71it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  3.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/2290 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 35%|███▌      | 807/2290 [00:00<00:00, 8061.30it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 2290/2290 [00:00<00:00, 8752.08it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  3.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/2290 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 37%|███▋      | 838/2290 [00:00<00:00, 8378.33it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 2290/2290 [00:00<00:00, 8864.98it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.69it/s]\u001B[A\u001B[A\n",
      "\n",
      " 50%|█████     | 4/8 [00:02<00:03,  1.31it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1267 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 9252.16it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  7.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1267 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 9195.55it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  7.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1267 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 9270.72it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  7.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1267 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 9242.91it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00,  7.05it/s]\u001B[A\u001B[A\n",
      "\n",
      " 62%|██████▎   | 5/8 [00:03<00:02,  1.44it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1319 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 9083.71it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  6.70it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1319 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 9265.51it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  6.78it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1319 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 8967.05it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  6.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1319 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 8183.30it/s][A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.44it/s]\u001B[A\u001B[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:03<00:01,  1.49it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 254/254 [00:00<00:00, 17764.47it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 254/254 [00:00<00:00, 16982.88it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 254/254 [00:00<00:00, 15825.68it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 254/254 [00:00<00:00, 15805.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 59.58it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/3498 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 21%|██        | 728/3498 [00:00<00:00, 7277.75it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 45%|████▍     | 1572/3498 [00:00<00:00, 7958.77it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 69%|██████▉   | 2417/3498 [00:00<00:00, 8180.82it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 3498/3498 [00:00<00:00, 8204.76it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.29it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/3498 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 22%|██▏       | 764/3498 [00:00<00:00, 7637.88it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 47%|████▋     | 1628/3498 [00:00<00:00, 8225.12it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 72%|███████▏  | 2521/3498 [00:00<00:00, 8546.45it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 3498/3498 [00:00<00:00, 8524.56it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  2.35it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/3498 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 20%|██        | 705/3498 [00:00<00:00, 7044.01it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 45%|████▌     | 1587/3498 [00:00<00:00, 8086.35it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 70%|███████   | 2464/3498 [00:00<00:00, 8393.25it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 3498/3498 [00:00<00:00, 8310.09it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  2.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "  0%|          | 0/3498 [00:00<?, ?it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 23%|██▎       | 808/3498 [00:00<00:00, 8070.89it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 49%|████▉     | 1706/3498 [00:00<00:00, 8602.12it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      " 74%|███████▍  | 2590/3498 [00:00<00:00, 8709.34it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 3498/3498 [00:00<00:00, 8613.01it/s]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "100%|██████████| 8/8 [00:05<00:00,  1.40it/s]\u001B[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.22s/it]\n"
     ]
    }
   ],
   "source": [
    "for model_path in tqdm(model_paths):\n",
    "    task_paths = [task for task in model_path.iterdir() if task.is_dir()]\n",
    "    for task_path in tqdm(task_paths):\n",
    "        pe_paths = [pe for pe in task_path.iterdir() if pe.is_dir()]\n",
    "        for pe_path in tqdm(pe_paths):\n",
    "            files = list(pe_path.glob(\"*.json\"))\n",
    "            files = [file for file in files if \"summary\" not in file.name]\n",
    "            for file in tqdm(files):\n",
    "                with open(file, \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                if \"finish_reason: SAFETY\" in data[\"response\"] or \"block_reason: SAFETY\" in data[\"response\"]:\n",
    "                    logger.info(f\"Correcting {file} with {data['response']}\")\n",
    "                    data[\"response\"] = \"\"\n",
    "                    \n",
    "                    with open(file, \"w\") as f:\n",
    "                        json.dump(data, f, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T11:49:53.582730Z",
     "start_time": "2024-02-11T11:49:41.115606Z"
    }
   },
   "id": "3c8bf509c45d237c",
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
