{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-28T05:48:51.329278Z",
     "start_time": "2023-12-28T05:48:51.324676Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logs_path = Path(\"logs\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T05:49:02.281579Z",
     "start_time": "2023-12-28T05:49:02.270423Z"
    }
   },
   "id": "4d28455235e79416",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "log_files = sorted([f for f in logs_path.iterdir() if f.is_file() and f.suffix == \".log\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T05:58:50.799445Z",
     "start_time": "2023-12-28T05:58:50.795288Z"
    }
   },
   "id": "d946091f21183ca0",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "main_program_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\| INFO     \\| __main__:run_evaluation:42 - Models: (.*) \\| Tasks: (.*) \\| Prompting: (.*)\")\n",
    "loop_combination_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\| INFO     \\| __main__:run_evaluation:78 - Running (.*) on (.*) with (.*)\")\n",
    "model_start_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\| INFO     \\| __main__:run_evaluation:106 - Running (.*)\")\n",
    "skip_evaluation_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\| INFO     \\| __main__:run_evaluation:110 - Skipping (\\d+)\") # OR\n",
    "start_prompt_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\| DEBUG    \\| __main__:run_evaluation:116 - (.*)\")\n",
    "inference_start_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\| INFO     \\| src.llms.(?:.*):inference:17 - Generating response from (.*)\")\n",
    "\n",
    "no_response_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\| DEBUG    \\| src.llms.(?:.*):inference:23 - No response generated, returning empty string\") # OR\n",
    "start_answer_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\| DEBUG    \\| src.llms.(?:.*):inference:25 - (.*)\")\n",
    "metadata_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d+) \\| SUCCESS  \\| src.llms.(?:.*):inference:26 - Response generated from (.*)\")\n",
    "\n",
    "failed_extraction_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d+) \\| DEBUG    \\| src.tasks.(?:.*):evaluate:76 - Could not extract prediction from response\") # OR\n",
    "failed_extraction_empty_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d+) \\| DEBUG    \\| src.tasks.(?:.*):evaluate:55 - Could not extract prediction from response as response is empty\")\n",
    "prediction_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d+) \\| DEBUG    \\| src.tasks.(?:.*):evaluate:74 - Prediction: (.*), Answer: (.*)\")\n",
    "\n",
    "current_progress_pattern = re.compile(r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d+) \\| INFO     \\| __main__:run_evaluation:140 - Correct: (\\d+)/(\\d+) \\((\\d+\\.\\d+)%\\)\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T06:39:04.974886Z",
     "start_time": "2023-12-28T06:39:04.969320Z"
    }
   },
   "id": "4cc1ba6efc7759f8",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(log_files[0], \"r\") as f:\n",
    "    log_lines = f.read().splitlines()\n",
    "    current_model = None\n",
    "    current_task = None\n",
    "    current_prompting = None\n",
    "    current_content = None\n",
    "    in_content_loop = False\n",
    "    obj = {\n",
    "        \"prompt\": None,\n",
    "        \n",
    "    }\n",
    "    counter = 0\n",
    "    for line in log_lines[:100]:\n",
    "        main_match = main_program_pattern.match(line)\n",
    "        loop_match = loop_combination_pattern.match(line)\n",
    "        if main_match:\n",
    "            print(\"=> Main match\")\n",
    "            log_time, models, tasks, prompting = main_match.groups()\n",
    "            models = models.split(\", \")\n",
    "            tasks = tasks.split(\", \")\n",
    "            prompting = prompting.split(\", \")\n",
    "        elif loop_match:\n",
    "            print(\"=> Loop match\")\n",
    "            log_time, model, task, prompting = loop_match.groups()\n",
    "            current_model = model\n",
    "            current_task = task\n",
    "            current_prompting = prompting\n",
    "        elif model_start_pattern.match(line):\n",
    "            print(\"=> [Model start match] \" + line)\n",
    "            log_time, model = model_start_pattern.match(line).groups()\n",
    "            current_model = model\n",
    "            is_current_a_prompt = False\n",
    "            is_current_a_response = False\n",
    "        elif skip_evaluation_pattern.match(line):\n",
    "            pass\n",
    "        elif start_prompt_pattern.match(line):\n",
    "            print(\"=> [Prompt match] \" + line)\n",
    "            log_time, content = start_prompt_pattern.match(line).groups()\n",
    "            current_content = content + \"\\n\"\n",
    "            in_content_loop = True\n",
    "            is_current_a_prompt = True\n",
    "        elif inference_start_pattern.match(line):\n",
    "            print(\"=> [Inference match] \" + line)\n",
    "            log_time, model = inference_start_pattern.match(line).groups()\n",
    "            in_content_loop = False\n",
    "            is_current_a_prompt = False\n",
    "        elif start_answer_pattern.match(line):\n",
    "            print(\"=> [Answer match] \" + line)\n",
    "            log_time, content = start_answer_pattern.match(line).groups()\n",
    "            current_content = content + \"\\n\"\n",
    "            in_content_loop = True\n",
    "            is_current_a_response = True\n",
    "        elif metadata_pattern.match(line):\n",
    "            print(\"=> [Metadata match] \" + line)\n",
    "            log_time, model = metadata_pattern.match(line).groups()\n",
    "            in_content_loop = False\n",
    "            is_current_a_response = False\n",
    "        elif no_response_pattern.match(line):\n",
    "            print(\"=> [No response match] \" + line)\n",
    "            log_time = no_response_pattern.match(line).groups()[0]\n",
    "            in_content_loop = False\n",
    "            is_current_a_response = False\n",
    "        elif failed_extraction_pattern.match(line):\n",
    "            print(\"=> [Failed extraction match] \" + line)\n",
    "            log_time = failed_extraction_pattern.match(line).groups()[0]\n",
    "            in_content_loop = False\n",
    "            is_current_a_response = False\n",
    "        elif failed_extraction_empty_pattern.match(line):\n",
    "            print(\"=> [Failed extraction empty match] \" + line)\n",
    "            log_time = failed_extraction_empty_pattern.match(line).groups()[0]\n",
    "            in_content_loop = False\n",
    "            is_current_a_response = False\n",
    "        elif prediction_pattern.match(line):\n",
    "            print(\"=> [Prediction match] \" + line)\n",
    "            log_time, prediction, answer = prediction_pattern.match(line).groups()\n",
    "            in_content_loop = False\n",
    "            is_current_a_response = False\n",
    "        elif current_progress_pattern.match(line):\n",
    "            print(\"=> [Progress match] \" + line)\n",
    "            log_time, correct, total, percentage = current_progress_pattern.match(line).groups()\n",
    "            in_content_loop = False\n",
    "            is_current_a_response = False\n",
    "        elif in_content_loop:\n",
    "            print(\"=> [ADD] \" + line)\n",
    "            current_content += line + \"\\n\"\n",
    "        else:\n",
    "            raise Exception(\"Unknown line: \" + line)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ee58d6cdfd8575b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
